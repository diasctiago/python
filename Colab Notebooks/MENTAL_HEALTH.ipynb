{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MENTAL_HEALTH.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"77f05608e8694aaeb64ab0a2637c79d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_09c2dc52ff984bfcb89dd30c48a4e79d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d67bd9b18c984566b32b3769ddd1b47c","IPY_MODEL_9aebe0aa830a4b75b49f1de2e1cf6db2"]}},"09c2dc52ff984bfcb89dd30c48a4e79d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d67bd9b18c984566b32b3769ddd1b47c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_982b994cd78d4881932afc20e32b6645","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d4597a50f9d4165bd9ca8684d028a1b"}},"9aebe0aa830a4b75b49f1de2e1cf6db2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e12a56a0550d496f9e51e45e6d37e749","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 676B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef08e82ce1784f348159220f3742941b"}},"982b994cd78d4881932afc20e32b6645":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d4597a50f9d4165bd9ca8684d028a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e12a56a0550d496f9e51e45e6d37e749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ef08e82ce1784f348159220f3742941b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fbd31c61bba46f8abf5f19c16ab8021":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e0a96e34e1ea42e18f3bf36bf476d47c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dec334504d264040bdd7537751f9d05e","IPY_MODEL_f2527397c9324d2fa2a2c5f45dbcf9f2"]}},"e0a96e34e1ea42e18f3bf36bf476d47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dec334504d264040bdd7537751f9d05e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_777d15124dce4835998be0b4cdc6f5aa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6f5a3d0a5074f6cadf436ce7aca69f1"}},"f2527397c9324d2fa2a2c5f45dbcf9f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2bc28fb2f7f44a769df8ac625e9a790e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 801kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38108c58f7164c6baca080bf58c5c0e4"}},"777d15124dce4835998be0b4cdc6f5aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f6f5a3d0a5074f6cadf436ce7aca69f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2bc28fb2f7f44a769df8ac625e9a790e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38108c58f7164c6baca080bf58c5c0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd8778f0f760469d93d0e580090ca506":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_14e65826d2ff4d88ac925877d87f43bb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_adaa18fcbbc74da2a816cc0bd137cce6","IPY_MODEL_a11e4dbcb6614b48b80b0986db957965"]}},"14e65826d2ff4d88ac925877d87f43bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"adaa18fcbbc74da2a816cc0bd137cce6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_328b95085afb4c3ea722893fba1eb50a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":536063208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":536063208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f9647fc81ef4deca8c6d8e7d803aaa6"}},"a11e4dbcb6614b48b80b0986db957965":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_baad674e8c274b449179c3c71c08c32a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 536M/536M [00:16&lt;00:00, 31.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13c3ea419615459b8f486fc5a41e1f40"}},"328b95085afb4c3ea722893fba1eb50a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3f9647fc81ef4deca8c6d8e7d803aaa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"baad674e8c274b449179c3c71c08c32a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13c3ea419615459b8f486fc5a41e1f40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"1HKCL_ZTRZnk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":785},"executionInfo":{"status":"ok","timestamp":1599085292594,"user_tz":180,"elapsed":10212,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"4fd76532-b49f-4c4b-e2eb-a5413907985e"},"source":[" !pip install transformers --upgrade\n"," !pip install wordninja"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n","\u001b[K     |████████████████████████████████| 890kB 4.5MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 14.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 48.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 47.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=10c6db3ab73609ec3020e320b549199f8de51810f82b971021da6d1ef3e398d6\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n","Collecting wordninja\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/15/abe4af50f4be92b60c25e43c1c64d08453b51e46c32981d80b3aebec0260/wordninja-2.0.0.tar.gz (541kB)\n","\u001b[K     |████████████████████████████████| 542kB 4.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: wordninja\n","  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wordninja: filename=wordninja-2.0.0-cp36-none-any.whl size=541553 sha256=6908d4bbd77eac59d9a030590366505c8dd0b6afc86744348c51fd84d961f4de\n","  Stored in directory: /root/.cache/pip/wheels/22/46/06/9b6d10ed02c85e93c3bb33ac50e2d368b2586248f192a2e22a\n","Successfully built wordninja\n","Installing collected packages: wordninja\n","Successfully installed wordninja-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DPBAhvzNDaKa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085302050,"user_tz":180,"elapsed":19656,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["from textblob import TextBlob\n","import wordninja\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer, TFBertLMHeadModel\n","from string import punctuation\n","from tensorflow.data import Dataset\n","import tensorflow as tf\n","import spacy\n","\n","spacy_nlp = spacy.load('en_core_web_sm')\n","\n","spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhIOn72UD_Nw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085302053,"user_tz":180,"elapsed":19650,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["#sample = pd.read_csv('./drive/My Drive/mentalhealth/SampleSubmission.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBVoxqvHD2co","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1599085302054,"user_tz":180,"elapsed":19640,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"c3c659e8-0cba-4c3b-eb23-d44b959b713b"},"source":["train = pd.read_csv('https://raw.githubusercontent.com/dadosaocubo/nlp/master/mental_health.csv')\n","train.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>I feel that it was better I dieAm happy</td>\n","      <td>Depression</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Why do I get hallucinations?</td>\n","      <td>Drugs</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I am stresseed due to lack of financial suppor...</td>\n","      <td>Depression</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Why is life important?</td>\n","      <td>Suicide</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>How could I be helped to go through the depres...</td>\n","      <td>Depression</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID                                               text       label\n","0   0            I feel that it was better I dieAm happy  Depression\n","1   1                       Why do I get hallucinations?       Drugs\n","2   2  I am stresseed due to lack of financial suppor...  Depression\n","3   3                             Why is life important?     Suicide\n","4   4  How could I be helped to go through the depres...  Depression"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"5CF-XH2Z8cyT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085302054,"user_tz":180,"elapsed":19630,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["train['text'] = train['text'].apply(lambda row: \" \".join([word.translate(str.maketrans('', '', punctuation)) for word in row.split()]))\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VWzEbG086_l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085302476,"user_tz":180,"elapsed":20044,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["train['text'] = train['text'].apply(lambda row: \" \".join([\" \".join(wordninja.split(word)) for word in row.split()]))\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"flJnb9K14-Ap","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085311621,"user_tz":180,"elapsed":29181,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["train['text'] = train['text'].apply(lambda x: \" \".join([str(TextBlob(i).correct()) for i in x.split()]))\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXqfJEPH9Aub","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085311625,"user_tz":180,"elapsed":29176,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["train['text'] = train['text'].str.replace('\\d+', '')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHKhHtDFIlId","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085311626,"user_tz":180,"elapsed":29170,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["train['text'] = train['text'].apply(lambda row: \" \".join([word for word in row.split() if word not in spacy_stopwords]))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"cRkS3_RpK0fd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599085311627,"user_tz":180,"elapsed":29161,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"3a616099-a305-4ff4-ca70-b0c67f91f465"},"source":["MAX_LEN = train.text.str.len().max()\n","MAX_LEN"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["121"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"lRVtgnUFJYSN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1599085325610,"user_tz":180,"elapsed":43134,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"8251c74d-34b4-43d0-e016-378ddd698654"},"source":["labels = pd.get_dummies(train['label'])\n","labels = tf.convert_to_tensor(labels)\n","labels"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(616, 4), dtype=uint8, numpy=\n","array([[0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       ...,\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0]], dtype=uint8)>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"wq1kQffprNqw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["77f05608e8694aaeb64ab0a2637c79d2","09c2dc52ff984bfcb89dd30c48a4e79d","d67bd9b18c984566b32b3769ddd1b47c","9aebe0aa830a4b75b49f1de2e1cf6db2","982b994cd78d4881932afc20e32b6645","5d4597a50f9d4165bd9ca8684d028a1b","e12a56a0550d496f9e51e45e6d37e749","ef08e82ce1784f348159220f3742941b","2fbd31c61bba46f8abf5f19c16ab8021","e0a96e34e1ea42e18f3bf36bf476d47c","dec334504d264040bdd7537751f9d05e","f2527397c9324d2fa2a2c5f45dbcf9f2","777d15124dce4835998be0b4cdc6f5aa","f6f5a3d0a5074f6cadf436ce7aca69f1","2bc28fb2f7f44a769df8ac625e9a790e","38108c58f7164c6baca080bf58c5c0e4","dd8778f0f760469d93d0e580090ca506","14e65826d2ff4d88ac925877d87f43bb","adaa18fcbbc74da2a816cc0bd137cce6","a11e4dbcb6614b48b80b0986db957965","328b95085afb4c3ea722893fba1eb50a","3f9647fc81ef4deca8c6d8e7d803aaa6","baad674e8c274b449179c3c71c08c32a","13c3ea419615459b8f486fc5a41e1f40"]},"executionInfo":{"status":"ok","timestamp":1599085347460,"user_tz":180,"elapsed":64972,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"9c50807b-0a9f-4c93-8517-787bfebbc6c2"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","bert_model = TFBertLMHeadModel.from_pretrained(\"bert-base-uncased\")"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77f05608e8694aaeb64ab0a2637c79d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fbd31c61bba46f8abf5f19c16ab8021","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd8778f0f760469d93d0e580090ca506","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["If you want to use `TFBertLMHeadModel` as a standalone, add `is_decoder=True.`\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertLMHeadModel: ['nsp___cls']\n","- This IS expected if you are initializing TFBertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertLMHeadModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertLMHeadModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mIrWFUtG73i-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085347461,"user_tz":180,"elapsed":64963,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["text_encode = tokenizer.batch_encode_plus(train['text'], padding='max_length', return_tensors='tf', max_length=MAX_LEN)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPHp9_aECrIf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085347462,"user_tz":180,"elapsed":64956,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["ids = text_encode['input_ids']\n","tks = text_encode['token_type_ids']\n","mask = text_encode['attention_mask']"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2vUPSACFrA4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599085439783,"user_tz":180,"elapsed":807,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["def get_model():\n","  ids = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n","  mask = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\n","  tks = tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='token_type_ids')\n","\n","  x = bert_model(inputs=ids, attention_mask=mask, token_type_ids=tks)[0]\n","  x = x[:, 0, :]\n","  x = tf.keras.layers.Dense(4, activation='sigmoid')(x)\n","  model = tf.keras.Model(inputs=(ids, mask, tks), outputs=x)\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n","  return model"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IBSISGoqzuX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1599085443767,"user_tz":180,"elapsed":2295,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"e9f2745b-4385-4bd4-a571-0c20a31fa4b5"},"source":["model = get_model()\n","model.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Model: \"functional_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 121)]        0                                            \n","__________________________________________________________________________________________________\n","attention_mask (InputLayer)     [(None, 121)]        0                                            \n","__________________________________________________________________________________________________\n","token_type_ids (InputLayer)     [(None, 121)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_lm_head_model (TFBertLM ((None, 121, 30522), 110104890   input_ids[0][0]                  \n","                                                                 attention_mask[0][0]             \n","                                                                 token_type_ids[0][0]             \n","__________________________________________________________________________________________________\n","tf_op_layer_strided_slice_1 (Te [(None, 30522)]      0           tf_bert_lm_head_model[1][0]      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 4)            122092      tf_op_layer_strided_slice_1[0][0]\n","==================================================================================================\n","Total params: 110,226,982\n","Trainable params: 110,226,982\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jl9oFy92F_h7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"status":"error","timestamp":1599085458956,"user_tz":180,"elapsed":16034,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}},"outputId":"2fb29bc8-bf82-49d5-8ef5-e114c98d59a0"},"source":["model.fit((ids, mask, tks), labels, epochs=10)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_lm_head_model/bert/pooler/dense/kernel:0', 'tf_bert_lm_head_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_lm_head_model/bert/pooler/dense/kernel:0', 'tf_bert_lm_head_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_lm_head_model/bert/pooler/dense/kernel:0', 'tf_bert_lm_head_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_lm_head_model/bert/pooler/dense/kernel:0', 'tf_bert_lm_head_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-10b7a02d5de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  logits and labels must have the same first dimension, got logits shape [32,4] and labels shape [128]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-20-10b7a02d5de7>:1) ]]\n\t [[gradient_tape/functional_3/tf_bert_lm_head_model/bert/embeddings/token_type_embeddings/embedding_lookup/Reshape/_590]]\n  (1) Invalid argument:  logits and labels must have the same first dimension, got logits shape [32,4] and labels shape [128]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-20-10b7a02d5de7>:1) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_58296]\n\nFunction call stack:\ntrain_function -> train_function\n"]}]},{"cell_type":"code","metadata":{"id":"ANWqnk_yzFc5","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599085370009,"user_tz":180,"elapsed":87466,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["predictions = model.predict((ids, mask))\n","predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eihxFL4ukRsE","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599085370016,"user_tz":180,"elapsed":87466,"user":{"displayName":"Tiago Dias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW4O_25wWQwVNJvj8cP-mYxouZ1TLUXKUrN-to2JQ=s64","userId":"11325234452599299452"}}},"source":["# df = pd.DataFrame(predictions, columns=['Depression',\t'Alcohol',\t'Suicide',\t'Drugs'])\n","# df = pd.concat([sample['ID'], df], axis=1)\n","\n","# x = df['Alcohol'].copy() #Invert\n","# df['Alcohol'] = df['Depression'].copy()\n","# df['Depression'] = x\n","\n","# x = df['Suicide'].copy() #Invert\n","# df['Suicide'] = df['Drugs'].copy()\n","# df['Drugs'] = x\n","\n","# df.to_csv('health.csv', index=False)\n","# df.head()"],"execution_count":null,"outputs":[]}]}